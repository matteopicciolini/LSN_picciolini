{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4becced",
   "metadata": {},
   "source": [
    "Matteo Picciolini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83793037",
   "metadata": {},
   "source": [
    "# Esercitazione 12 - Esercizi 12.2 e 12.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c527ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 17:29:37.527021: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-26 17:29:37.571365: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-26 17:29:37.572488: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-26 17:29:38.432032: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD, Adam, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "from keras.layers import Flatten, Conv2D, MaxPooling2D\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed) # fix random seed\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "#center graphs\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac390e4d",
   "metadata": {},
   "source": [
    "## Exercise 12.2\n",
    "\n",
    "Change the architecture of your DNN using convolutional layers. Use `Conv2D`, `MaxPooling2D`, `Dropout`, but also do not forget `Flatten`, a standard `Dense` layer and `soft-max` in the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e79a3a",
   "metadata": {},
   "source": [
    "### Risoluzione\n",
    "\n",
    "Finora ho considerato ogni campione di dati `MNIST` come un vettore 1D di lunghezza $(28x28)$. D'altra parte, in ogni cifra scritta a mano ci sono correlazioni spaziali locali tra i pixel, ma anche invarianza traslazionale, di cui si vorrebbe approfittare per migliorare l'accuratezza del modello. A tal fine, prima di tutto è necessario ridimensionare i dati di input di addestramento e di test come segue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4f5900a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28)\n",
      "Y_train shape: (60000,)\n",
      "X_test shape: (10000, 28, 28)\n",
      "Y_test shape: (10000,)\n",
      "Before to_categorical: \n",
      "X_train shape:  (60000, 28, 28, 1)\n",
      "Y_train shape:  (60000,)\n",
      "Train samples:  60000\n",
      "Test samples:  10000\n",
      "After to_categorical: \n",
      "X_train shape: (60000, 28, 28, 1)\n",
      "Y_train shape: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 28, 28 # input image dimensions (pixels) \n",
    "num_classes = 10 # output: 10 digits\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "print('X_train shape:', X_train.shape) # l'input\n",
    "print('Y_train shape:', Y_train.shape) # label, ovvero gli output\n",
    "print('X_test shape:', X_test.shape) # l'input\n",
    "print('Y_test shape:', Y_test.shape) # label, ovvero gli output\n",
    "\n",
    "\n",
    "if keras.backend.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "print('Before to_categorical: ')\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('Y_train shape: ', Y_train.shape)\n",
    "print('Train samples: ', X_train.shape[0])\n",
    "print('Test samples: ', X_test.shape[0])\n",
    "\n",
    "# cast floats to single precision, and rescale to interval [0,1]\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255\n",
    "\n",
    "# convert class vectors to binary class matrices, e.g. for use with categorical_crossentropy\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n",
    "print('After to_categorical: ')\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86b7f55",
   "metadata": {},
   "source": [
    "A questo punto, lavorando sul codice dell'esercizio precedente, provo a migliorare le performance della rete, modificandone l'architettura facendola diventare una *Convolutional Neural Network*. Una Convolutional Neural Network (CNN), o rete neurale convoluzionale, è un tipo di rete neurale artificiale progettata per l'elaborazione e l'analisi di dati strutturati, in particolare immagini. \n",
    "\n",
    "\n",
    "A differenza delle reti neurali tradizionali, le CNN sfruttano specificamente l'operazione di convoluzione per estrarre e apprendere automaticamente le caratteristiche rilevanti dalle immagini. Questo processo di convoluzione coinvolge l'applicazione di filtri chiamati kernel su diverse regioni dell'immagine per individuare pattern, bordi, texture e altre informazioni visive significative.\n",
    "\n",
    "Le CNN sono caratterizzate dalla presenza di strati di convoluzione seguiti da strati di pooling, che riducono progressivamente le dimensioni dell'immagine. Gli strati convoluzionali estraggono e combinano le caratteristiche locali, mentre gli strati di pooling riducono la dimensione spaziale delle caratteristiche mantenendo le informazioni più rilevanti. Successivamente, gli strati completamente connessi aggregano le caratteristiche estratte e le utilizzano per la classificazione o altre attività di elaborazione.\n",
    "\n",
    "Utilizzo, quindi, alcuni convolutional *layers* per risolvere la *task*:\n",
    "- Il layer `Conv2D` è un layer convoluzionale che esegue una convoluzione bidimensionale per estrarre alcune caratteristiche rilevanti delle immagini, come bordi e/o pattern, generando una mappa delle caratteristiche convolute.\n",
    "- Il layer `MaxPooling2D` riduce l'immagine di input prendendo il valore massimo di uno dei pixel all'interno di una finestra di dimensioni fissate.\n",
    "- Il layer `Dropout` disattiva alcuni neuroni durante l'addestramento per rendere più difficile l'apprendimento e rendere il modello più robusto.\n",
    "- Il layer `Flatten` trasforma l'input da una forma 2D a una forma monodimensionale, consentendo l'utilizzo di altri layer di tipo Dense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bead3ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled successfully and ready to be trained.\n"
     ]
    }
   ],
   "source": [
    "def create_CDNN():\n",
    "    model = Sequential()\n",
    "    #----------create layers-------------                                                    \n",
    "    model.add(Conv2D(10, kernel_size = (5, 5),\n",
    "                     activation = 'relu',\n",
    "                     input_shape = input_shape))\n",
    "    model.add(Conv2D(64, kernel_size = (5, 5), activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling2D(pool_size = (4, 4)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation = 'relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def compile_model():\n",
    "    # create the model\n",
    "    model = create_CDNN()\n",
    "    # compile the model\n",
    "    model.compile(loss = keras.losses.categorical_crossentropy,\n",
    "                  optimizer = 'nadam',\n",
    "                  metrics = ['acc'])\n",
    "    return model\n",
    "\n",
    "print('Model compiled successfully and ready to be trained.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb5b84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 17:29:40.834252: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1875/1875 [==============================] - 53s 27ms/step - loss: 0.1733 - acc: 0.9488 - val_loss: 0.0873 - val_acc: 0.9840\n",
      "Epoch 2/8\n",
      "1875/1875 [==============================] - 55s 29ms/step - loss: 0.0586 - acc: 0.9823 - val_loss: 0.0663 - val_acc: 0.9873\n",
      "Epoch 3/8\n",
      "1875/1875 [==============================] - 55s 29ms/step - loss: 0.0440 - acc: 0.9865 - val_loss: 0.0575 - val_acc: 0.9864\n",
      "Epoch 4/8\n",
      " 309/1875 [===>..........................] - ETA: 43s - loss: 0.0338 - acc: 0.9900"
     ]
    }
   ],
   "source": [
    "my_batch_size = 32\n",
    "epochs = 8\n",
    "\n",
    "model_CDNN = compile_model()\n",
    "\n",
    "\n",
    "history = model_CDNN.fit(X_train, Y_train,\n",
    "                        batch_size = my_batch_size,\n",
    "                        epochs = epochs,\n",
    "                        verbose = 1,\n",
    "                        validation_data = (X_test, Y_test)\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1f5c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "score = model_CDNN.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# look into training history\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.ylabel('model accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa03080",
   "metadata": {},
   "source": [
    "#### Commenti\n",
    "Rispetto all'esercizio precedente la *loss* e l'*accuracy* sono certametne migliorate, soprattutto confrontandole a parità di numero di epoche. La bontà del modello è, però, garantita a spese di un tempo computazionale per epoca decisamente maggiore, dell'ordine di $\\sim 5$ volte il tempo di allenamento di un'epoca dell'esercizio $12.1$.\n",
    "\n",
    "Una volta allenata la rete e fissati i parametri, quindi, si ottiene dopo $7$ epoche un valore di *loss* per il test pari $0.04$ e un valore di *accuracy* del $98,9\\%$. Rispetto all'esercizio precedente, ho utilizzato un ottimizzatore diverso: `nadam`, che permette di ottenere risultati molto migliori rispetto allo stesso modello con l'ottimizzatore `adagrad`, soprattutto in termini di *loss*. Inoltre, con `nadam` ho potuto fermarmi alla settima epoca, perchè i risultati erano già ottimi, mentre con `adagrad` sono dovuto andare oltre la $10$ per ottenere comuqnue risultati peggiori di questi che sono esposti ora."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d04761",
   "metadata": {},
   "source": [
    "## Exercise 12.3\n",
    "\n",
    "Use the `gimp` application to create 10 pictures of your \"handwritten\" digits, import them in your jupyter-notebook and try to see if your CNN is able to recognize your handwritten digits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f3e5a4",
   "metadata": {},
   "source": [
    "### Risoluzione\n",
    "Ho usato l'applicazione `gimp` per generare alcune cifre per testare personalmente la rete. Riporto di seguito i risultati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6dd363",
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_filenames = [ \"../../Data/12.3_zero.png\",\n",
    "                    \"../../Data/12.3_one.png\",\n",
    "                    \"../../Data/12.3_two.png\",\n",
    "                    \"../../Data/12.3_three.png\",\n",
    "                    \"../../Data/12.3_four.png\",\n",
    "                    \"../../Data/12.3_five.png\",\n",
    "                    \"../../Data/12.3_six.png\",\n",
    "                    \"../../Data/12.3_seven.png\",\n",
    "                    \"../../Data/12.3_eight.png\",\n",
    "                    \"../../Data/12.3_nine.png\",\n",
    "                    \"../../Data/12.3_x.png\"]\n",
    "data = []\n",
    "\n",
    "for digit_filename in digit_filenames:\n",
    "    digit_in = Image.open(digit_filename).convert('L')\n",
    "\n",
    "    ydim, xdim = digit_in.size\n",
    "    pix=digit_in.load()\n",
    "    img = np.zeros((xdim, ydim))\n",
    "    for j in range(ydim):\n",
    "        for i in range(xdim):\n",
    "            img[i,j] = pix[j, i] / 255\n",
    "    data.append(img)\n",
    "\n",
    "\n",
    "predictions = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "for i in range(0, 11):\n",
    "    data[i] = data[i].reshape(1, xdim, ydim, 1)\n",
    "    predictions[i] = model_CDNN.predict(data[i])\n",
    "    data[i] = data[i].reshape(xdim,ydim)\n",
    "\n",
    "plt.figure(figsize = (15, 4))\n",
    "for i in range(11):    \n",
    "    ax = plt.subplot(1, 11, i + 1)    \n",
    "    plt.imshow(data[i], cmap = 'gray')\n",
    "    if i != 10:\n",
    "        plt.title(\"Digit: \"+ str(i) + \"\\nPredicted: {}\".format(np.argmax(predictions[i])))\n",
    "    else:\n",
    "        plt.title(\"Digit: x \\nPredicted: {}\".format(np.argmax(predictions[i])))\n",
    "    plt.axis('off') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12f1bf6",
   "metadata": {},
   "source": [
    "#### Commenti\n",
    "I risultati mostrano un'ottimo accordo. L'unica cifra che viene predetta in maniera errata è la cifra $7$, che ho volutamente scrivere in modo non usuale, proprio per testare l'efficacia della rete nel riconoscere anche cifre con tratti non usuali. Il limite della rete è, evidentemente, proprio questo.\n",
    "Ho provato anche a scrivere alcune cifre leggermente ruotate (come l'$8$) o leggermente traslate (come il $3$). La rete è stata, però, in grado di riconoscere ugualmente la cifra. Trovo interessante che lo stesso modello con l'ottimizzatore `adagrad` restituisse predizioni di queste cifre scritte da me sbagliate, nonostante l'*accuray* coi dati di *test* fosse di circa il $95\\%$.\n",
    "\n",
    "Ho voluto anche \"ingannare\" la rete provando a scrivere un simbolo che non corrisponde a nessuna cifra. Il simbolo che ho utilizzato è \"x\", e trovo curioso che la predizione della rete sia proprio $8$, perchè è l'unica cifra con un pattern simile (il centro della cifra $8$ è simile a una \"x\"). Questo significa che la rete ha riconoscituo quel pattern e ha assunto che si trattasse di un $8$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
